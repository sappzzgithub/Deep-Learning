{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "841aa1de-36ed-4af7-85c7-9750d883b8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "349fb4b4-297f-4e28-8e40-c91ca3e6262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Admission_Predict_Ver1.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "42bba99d-09bf-4330-a0fd-121d65a4745b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "da931fc4-28e0-42c7-8b46-f12ced6397d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f8eafc5f-cb10-4af9-9dc3-184eb88ac2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial No.           0\n",
       "GRE Score            0\n",
       "TOEFL Score          0\n",
       "University Rating    0\n",
       "SOP                  0\n",
       "LOR                  0\n",
       "CGPA                 0\n",
       "Research             0\n",
       "Chance of Admit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d7b828a0-b7cc-472a-b7fc-09af0a5db8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0          337          118                  4  4.5   4.5  9.65         1   \n",
       "1          324          107                  4  4.0   4.5  8.87         1   \n",
       "2          316          104                  3  3.0   3.5  8.00         1   \n",
       "3          322          110                  3  3.5   2.5  8.67         1   \n",
       "4          314          103                  2  2.0   3.0  8.21         0   \n",
       "..         ...          ...                ...  ...   ...   ...       ...   \n",
       "495        332          108                  5  4.5   4.0  9.02         1   \n",
       "496        337          117                  5  5.0   5.0  9.87         1   \n",
       "497        330          120                  5  4.5   5.0  9.56         1   \n",
       "498        312          103                  4  4.0   5.0  8.43         0   \n",
       "499        327          113                  4  4.5   4.5  9.04         0   \n",
       "\n",
       "     Chance of Admit   \n",
       "0                0.92  \n",
       "1                0.76  \n",
       "2                0.72  \n",
       "3                0.80  \n",
       "4                0.65  \n",
       "..                ...  \n",
       "495              0.87  \n",
       "496              0.96  \n",
       "497              0.93  \n",
       "498              0.73  \n",
       "499              0.84  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns = 'Serial No.',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c0267574-ad43-43f3-bc43-f2c23a1df550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Serial No.', 'GRE Score', 'TOEFL Score', 'University Rating', 'SOP',\n",
      "       'LOR ', 'CGPA', 'Research', 'Chance of Admit '],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e7ac1e52-a260-4a25-ba68-dcd7daad370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Chance of Admit ', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e8b6de5d-0e7d-4887-bb0e-f89502079160",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Chance of Admit ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c3e7a315-5915-4dcf-8d1d-7e2126156aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5d2b5000-ab13-41f0-a5c0-42cefe057ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>239</td>\n",
       "      <td>310</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>439</td>\n",
       "      <td>318</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>476</td>\n",
       "      <td>300</td>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "      <td>300</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>381</td>\n",
       "      <td>322</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>256</td>\n",
       "      <td>307</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73</td>\n",
       "      <td>321</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>397</td>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>236</td>\n",
       "      <td>326</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>300</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "238         239        310          104                  3  2.0   3.5  8.37   \n",
       "438         439        318          110                  1  2.5   3.5  8.54   \n",
       "475         476        300          101                  3  3.5   2.5  7.88   \n",
       "58           59        300           99                  1  3.0   2.0  6.80   \n",
       "380         381        322          104                  3  3.5   4.0  8.84   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "255         256        307          110                  4  4.0   4.5  8.37   \n",
       "72           73        321          111                  5  5.0   5.0  9.45   \n",
       "396         397        325          107                  3  3.0   3.5  9.11   \n",
       "235         236        326          111                  5  4.5   4.0  9.23   \n",
       "37           38        300          105                  1  1.0   2.0  7.80   \n",
       "\n",
       "     Research  \n",
       "238         0  \n",
       "438         1  \n",
       "475         0  \n",
       "58          1  \n",
       "380         1  \n",
       "..        ...  \n",
       "255         0  \n",
       "72          1  \n",
       "396         1  \n",
       "235         1  \n",
       "37          0  \n",
       "\n",
       "[400 rows x 8 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fc733d1f-c099-4c3a-902a-55af10d0a1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238    0.70\n",
       "438    0.67\n",
       "475    0.59\n",
       "58     0.36\n",
       "380    0.78\n",
       "       ... \n",
       "255    0.79\n",
       "72     0.93\n",
       "396    0.84\n",
       "235    0.88\n",
       "37     0.58\n",
       "Name: Chance of Admit , Length: 400, dtype: float64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cf3dff63-b56b-4a4b-836b-af6696b76f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0717aa3d-8803-4957-a91d-855282d2b846",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "133df823-055b-4d06-973d-3737c909eb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47695391, 0.4       , 0.42857143, ..., 0.57142857, 0.50320513,\n",
       "        0.        ],\n",
       "       [0.87775551, 0.56      , 0.64285714, ..., 0.57142857, 0.55769231,\n",
       "        1.        ],\n",
       "       [0.95190381, 0.2       , 0.32142857, ..., 0.28571429, 0.34615385,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.79358717, 0.7       , 0.53571429, ..., 0.57142857, 0.74038462,\n",
       "        1.        ],\n",
       "       [0.47094188, 0.72      , 0.67857143, ..., 0.71428571, 0.77884615,\n",
       "        1.        ],\n",
       "       [0.0741483 , 0.2       , 0.46428571, ..., 0.14285714, 0.32051282,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5cbab345-566e-46c3-8d0b-139a234c4aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "608bca3a-2d9d-49a2-8f23-90662348ccd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Model Building\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim = x_train.shape[1], activation = 'relu'))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e61e7ee8-e523-4a60-bbff-d53f4f09a6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m576\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,689</span> (10.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,689\u001b[0m (10.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,689</span> (10.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,689\u001b[0m (10.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9aa0ffa0-b15d-4077-9c66-aee19447551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a5c81c11-bcfa-4dbc-b117-3ef256d226ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2310 - val_loss: 0.0242\n",
      "Epoch 2/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.0325 - val_loss: 0.0266\n",
      "Epoch 3/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 0.0202 - val_loss: 0.0108\n",
      "Epoch 4/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 0.0113 - val_loss: 0.0069\n",
      "Epoch 5/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 0.0076 - val_loss: 0.0060\n",
      "Epoch 6/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 0.0053 - val_loss: 0.0056\n",
      "Epoch 7/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 8/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 9/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 10/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 11/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 12/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 13/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 14/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 15/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 16/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 17/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 18/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 19/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 20/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 21/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 22/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 23/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 24/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 25/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 26/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 27/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 28/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 29/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 30/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 31/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 32/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 33/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 34/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 35/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 36/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 37/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 38/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 39/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 40/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 41/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 42/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 43/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 44/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 45/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 46/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 47/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 48/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 49/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 50/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 51/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 52/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 53/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 54/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 55/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 56/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 57/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 58/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 59/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 60/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 61/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 62/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 63/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 64/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 65/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 66/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 67/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 68/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 69/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 70/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 71/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 72/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 73/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 74/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 75/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 76/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 77/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 78/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 79/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 80/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 81/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 82/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 83/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 84/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 85/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 86/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 87/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 88/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 89/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 90/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 91/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 92/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 93/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 94/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 95/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 96/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 97/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 98/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 99/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 100/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - loss: 0.0016 - val_loss: 0.0035\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 100, batch_size = 32, validation_data = (x_test,y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8aefada2-3f03-4d04-996e-3231b05cceb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/stepWARNING:tensorflow:5 out of the last 21 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x30cf55620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a09d6282-6bf9-4db1-be1e-d4f207488fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003470139563198549"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "7972a157-cd13-4811-b50a-f6b010643d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.820302440930115"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6dd2068d-0dd9-439e-93d3-f38c1c8a7aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x30dbd1ac0>]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3cb2a6-2bd6-41a0-8acf-03de4b1cdb2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
